OPENAI_API_KEY=your-openai-api-key
ANTHROPIC_API_KEY=your-anthropic-api-key
GEMINI_API_KEY=your-gemini-api-key
OPENROUTER_API_KEY=your-openrouter-api-key
Z_AI_API_KEY=your-zai-api-key
MOONSHOT_API_KEY=your-moonshot-api-key

# Ollama configuration (optional - defaults to http://127.0.0.1:11434)
# OLLAMA_HOST=http://127.0.0.1:11434

# Debug Mode Settings
# Set to "true" to enable debug mode (runs only one test with one model)
# DEBUG_MODE=false
# Optionally specify which test to run (defaults to first test if not specified)
# DEBUG_TEST=counter
# Optionally specify number of samples to generate in debug mode (defaults to 1)
# DEBUG_SAMPLES=5
# Optionally specify which provider to use (defaults to first provider if not specified)
# DEBUG_PROVIDER=openai
# Optionally specify which model to use (defaults to first model of the provider if not specified)
# DEBUG_MODEL=gpt-4o-2024-11-20

# OpenRouter Provider Selection (optional)
# Specify preferred provider routing strategy for OpenRouter requests
# See: https://openrouter.ai/docs/features/provider-routing
# OPENROUTER_PROVIDER=auto

# EXPERIMENTAL
# Enable parallel testing (disabled by default, consumes tokens very quickly!)
# PARALLEL_EXECUTION=true

# Retry Configuration for LLM API Calls
# Maximum number of retry attempts for failed LLM requests (default: 100)
# RETRY_MAX_ATTEMPTS=100
# Initial delay in milliseconds before first retry (default: 1000)
# RETRY_INITIAL_DELAY_MS=1000
# Maximum delay in milliseconds between retries (default: 30000)
# RETRY_MAX_DELAY_MS=30000
# Backoff factor for exponential delay increase (default: 2)
# RETRY_BACKOFF_FACTOR=2
