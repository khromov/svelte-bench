# Native SDK Providers (with extended features)
OPENAI_API_KEY=your-openai-api-key
ANTHROPIC_API_KEY=your-anthropic-api-key
GEMINI_API_KEY=your-gemini-api-key
OPENROUTER_API_KEY=your-openrouter-api-key
Z_AI_API_KEY=your-zai-api-key
MOONSHOT_API_KEY=your-moonshot-api-key

# Ollama configuration (optional - defaults to http://127.0.0.1:11434)
# OLLAMA_HOST=http://127.0.0.1:11434

# AI SDK Language Model Providers
# These providers are available through the Vercel AI SDK unified registry
# Configure any of the following to enable additional providers:

# Google Vertex AI
# GOOGLE_VERTEX_PROJECT=your-project-id
# GOOGLE_VERTEX_LOCATION=us-central1

# Azure OpenAI
# AZURE_API_KEY=your-azure-api-key
# AZURE_RESOURCE_NAME=your-resource-name

# xAI (Grok)
# XAI_API_KEY=your-xai-api-key

# Vercel
# VERCEL_API_KEY=your-vercel-api-key

# Mistral
# MISTRAL_API_KEY=your-mistral-api-key

# Cohere
# COHERE_API_KEY=your-cohere-api-key

# Amazon Bedrock
# AWS_ACCESS_KEY_ID=your-access-key-id
# AWS_SECRET_ACCESS_KEY=your-secret-access-key
# AWS_REGION=us-east-1

# Groq
# GROQ_API_KEY=your-groq-api-key

# DeepSeek
# DEEPSEEK_API_KEY=your-deepseek-api-key

# Cerebras
# CEREBRAS_API_KEY=your-cerebras-api-key

# Fireworks
# FIREWORKS_API_KEY=your-fireworks-api-key

# Together.ai
# TOGETHER_API_KEY=your-together-api-key

# Perplexity
# PERPLEXITY_API_KEY=your-perplexity-api-key

# DeepInfra
# DEEPINFRA_API_KEY=your-deepinfra-api-key

# Baseten
# BASETEN_API_KEY=your-baseten-api-key

# Hugging Face
# HUGGINGFACE_API_KEY=your-huggingface-api-key

# AI SDK Media Providers (Image/Video/Audio)
# Replicate
# REPLICATE_API_KEY=your-replicate-api-key

# Fal
# FAL_API_KEY=your-fal-api-key

# Luma
# LUMA_API_KEY=your-luma-api-key

# ElevenLabs
# ELEVENLABS_API_KEY=your-elevenlabs-api-key

# AssemblyAI
# ASSEMBLYAI_API_KEY=your-assemblyai-api-key

# Deepgram
# DEEPGRAM_API_KEY=your-deepgram-api-key

# Gladia
# GLADIA_API_KEY=your-gladia-api-key

# LMNT
# LMNT_API_KEY=your-lmnt-api-key

# Hume
# HUME_API_KEY=your-hume-api-key

# Rev.ai
# REVAI_API_KEY=your-revai-api-key

# Debug Mode Settings
# Set to "true" to enable debug mode (runs only one test with one model)
# DEBUG_MODE=false
# Optionally specify which test to run (defaults to first test if not specified)
# DEBUG_TEST=counter
# Optionally specify number of samples to generate in debug mode (defaults to 1)
# DEBUG_SAMPLES=5
# Optionally specify which provider to use (defaults to first provider if not specified)
# DEBUG_PROVIDER=openai
# Optionally specify which model to use (defaults to first model of the provider if not specified)
# DEBUG_MODEL=gpt-4o-2024-11-20

# OpenRouter Provider Selection (optional)
# Specify preferred provider routing strategy for OpenRouter requests
# See: https://openrouter.ai/docs/features/provider-routing
# OPENROUTER_PROVIDER=auto

# EXPERIMENTAL
# Enable parallel testing (disabled by default, consumes tokens very quickly!)
# PARALLEL_EXECUTION=true

# Retry Configuration for LLM API Calls
# Maximum number of retry attempts for failed LLM requests (default: 100)
# RETRY_MAX_ATTEMPTS=100
# Initial delay in milliseconds before first retry (default: 1000)
# RETRY_INITIAL_DELAY_MS=1000
# Maximum delay in milliseconds between retries (default: 30000)
# RETRY_MAX_DELAY_MS=30000
# Backoff factor for exponential delay increase (default: 2)
# RETRY_BACKOFF_FACTOR=2
